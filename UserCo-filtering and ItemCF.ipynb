{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top N问题，查看用户是否会给某部电影评分\n",
    "# dataset： MovieLens\n",
    "\n",
    "def SplitData(data,M,k,seed):\n",
    "    '''\n",
    "    Split data\n",
    "    M : experimental times(M-fold)\n",
    "    k: the test section\n",
    "    seed: random seed\n",
    "    '''\n",
    "    test = []\n",
    "    train = []\n",
    "    random.seed(seed)\n",
    "    for user, item in data:\n",
    "        if random.randint(0,M) == k:\n",
    "            test.append([user,item])\n",
    "        else:\n",
    "            train.append([user,item])\n",
    "    return train,test\n",
    "\n",
    "# 评价指标： 召回率，精确度，覆盖度,新颖度\n",
    "\n",
    "def Recall(train, test, N):\n",
    "    '''\n",
    "    N : top_N\n",
    "    '''\n",
    "    hit = 0\n",
    "    alls = 0\n",
    "    for user in train.keys():\n",
    "        tu = test[user] # 真实的样本\n",
    "        rank = GetRecommendation(user, N)\n",
    "        for item, pui in rank:\n",
    "            if item in tu:\n",
    "                hit += 1\n",
    "        alls += len(tu)\n",
    "    return hit / float(alls)\n",
    "\n",
    "def Precision(train, test, N):\n",
    "    hit = 0\n",
    "    alls = 0\n",
    "    for user in train.keys():\n",
    "        tu = test[user]\n",
    "        rank = GetRecommendation(user, N)\n",
    "        for item, pui in rank:\n",
    "            if item in tu:\n",
    "                hit += 1\n",
    "        alls += len(rank)\n",
    "    return hit / float(alls) # /(alls*1.0)\n",
    "    \n",
    "def Coverage(train, test, N):\n",
    "    recommend_items = set()\n",
    "    all_items = set()\n",
    "    for user in train.keys():\n",
    "        for item in train[user]:\n",
    "            all_items.add(item)\n",
    "        rank = GetRecommendation(user,N)\n",
    "        for item, pui in rank:\n",
    "            recommend_items.add(item)\n",
    "    return len(recommend_items)/(len(all_items)*1.0)\n",
    "\n",
    "def Popularity(train, test, N):\n",
    "    item_popularity = dict()\n",
    "    for user,items in train.items():\n",
    "        for item in items:\n",
    "            if item not in item_popularity:\n",
    "                item_popularity[item] = 0\n",
    "            item_popularity[item] += 1\n",
    "    ret = 0\n",
    "    n = 0\n",
    "    for user in train.keys():\n",
    "        rank = GetRecommendation(user, N)\n",
    "        for item, pui in rank:\n",
    "            ret += math.log(1+item_popularity[item])\n",
    "            n += 1\n",
    "    ret = ret/(n*1.0)\n",
    "    return ret\n",
    "\n",
    "def GiniIndex(p):\n",
    "    \"\"\"\n",
    "    p物品流行度\n",
    "    \"\"\"\n",
    "    j = 1\n",
    "    n = len(p)\n",
    "    G = 0\n",
    "    for item, weight in sorted(p.items(), key=itemgetter(1)):\n",
    "        G += (2*j - n - 1)*weights\n",
    "        j += 1 # 自己添加的\n",
    "    return G / float(n-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jaccard: $ w_{uv} = \\frac{N(u)\\cap N(v)}{N(u)\\cup N(v)}$  \n",
    "cosine: $w_{uv} = \\frac{N(u)\\cap N(v)}{\\sqrt{|N(u)||N(v)|}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cosine\n",
    "import math\n",
    "def UserSimilarityold(train):\n",
    "    '''\n",
    "    这种算法时间复杂度太大，所以一般不用\n",
    "    '''\n",
    "    W = dict()\n",
    "    for u in train.keys():\n",
    "        for v in train.keys():\n",
    "            if u == v:\n",
    "                continue\n",
    "            w[u][v] = len(train[u]&train[v])\n",
    "            w[u][v] /= math.sqrt(len(train[u]) * len(train[v] * 1.0))\n",
    "    return w\n",
    "\n",
    "def UserSimilarity(train):\n",
    "    \"\"\"\n",
    "    这个相似度实现的是，首先建立物品到用户的排序表；\n",
    "    如果说u，v客户同属于物品到用户排序表种第K个的话，C[u][k] = K\n",
    "    \"\"\"\n",
    "    # build inverse table for item_users(建立物品到用户的倒排表)\n",
    "    item_users = {}\n",
    "    for u, items in train.items():\n",
    "        #for i in items.keys():\n",
    "        for i in items:\n",
    "            if i not in item_users.keys():\n",
    "                item_users[i] = set()\n",
    "            item_users[i].add(u)\n",
    "            \n",
    "    # calculate co-rated items between users\n",
    "    C = {}\n",
    "    N = {}\n",
    "    for i, users in item_users.items():\n",
    "        for u in users:\n",
    "            if u not in N.keys():\n",
    "                N[u] = 0\n",
    "            if u not in C.keys():\n",
    "                C[u] = {}\n",
    "            N[u] += 1\n",
    "            for v in users:\n",
    "                if u == v:\n",
    "                    continue\n",
    "                if v not in C[u].keys():\n",
    "                    C[u][v] = 0\n",
    "                C[u][v] += 1\n",
    "    \n",
    "    # calculate finial similarity matrix W\n",
    "    w = {}\n",
    "    for u, related_users in C.items():\n",
    "        for v, cuv in related_users.items():\n",
    "            if u not in w.keys():\n",
    "                w[u] = {}\n",
    "            w[u][v] = cuv/math.sqrt(N[u]*N[v])\n",
    "    return w,N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A': 3, 'B': 2, 'C': 2, 'D': 3}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = {'A':['a','b','d'],'B':['a','c'],'C':['b','e'],'D':['c','d','e']}\n",
    "\n",
    "W,N = UserSimilarity(train)\n",
    "\n",
    "W['A']['B'] + W['A']['D']\n",
    "N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Recommend(user,train, W, K):\n",
    "    rank = {}\n",
    "    rvi = 1# 这个是用户对物品的兴趣度，可以自定义取值，\n",
    "    #当train是嵌套字典的时候，物品后面可以跟rvi值，train[user].keys()也就是用户一般浏览的物品\n",
    "    interacted_items = train[user]\n",
    "    # print(interacted_items)\n",
    "    similarity = sorted(W[user].items(),key = lambda x:x[1], reverse = True)[0:K]\n",
    "    for v, wuv in similarity: # 选取用户近似度排名前K名的\n",
    "        #print(v,wuv)\n",
    "        for i in train[v]: # 相似用户的物品\n",
    "            if i in interacted_items: # 过滤用户和相似用户都已经有的物品\n",
    "                # filter items user interacted before\n",
    "                continue\n",
    "            if i not in rank.keys():\n",
    "                rank[i] = 0\n",
    "            #print('rank',i,rank[i])\n",
    "            #print(wuv,rvi)\n",
    "            rank[i] += wuv*rvi\n",
    "            #print('rank',i,rank[i])\n",
    "    return rank\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'c': 0.7415816237971964, 'e': 0.7415816237971964}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Recommend('A',train,W,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "改进余弦相似度：\n",
    "对于余弦相似度的分子做一个惩罚项，也就是除以log(两个用户共同商品数量+1)\n",
    " $$w_{uv} = \\frac{\\sum_{i \\in N(u)\\cap N(v)}\\frac{1}{log(1+|N(i)|)}}{\\sqrt{|N(u)||N(v)|}}$$  \n",
    " N(i)是指对物品i有过惯量的用户的集合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def UserSimilarityChange(train):\n",
    "    # 建立物品用户表：\n",
    "    item_users = {}\n",
    "    for u, items in train.items():\n",
    "        for item in items:\n",
    "            if item not in item_users.keys():\n",
    "                item_users[key] = set()\n",
    "            item_users[key].add(u)\n",
    "            \n",
    "    # 计算用户之间的相似性：\n",
    "    C = {}\n",
    "    N = {}\n",
    "    for item, users in item_users.items:\n",
    "        for u in users:\n",
    "            if u not in N.keys():\n",
    "                N[u] = 0\n",
    "            N[u] += 1 # 用户u有过相关的物品数目\n",
    "            if u not in C.keys():\n",
    "                C[u] = {}\n",
    "            for v in users:\n",
    "                if u == v:\n",
    "                    continue\n",
    "                if v not in C[u].keys():\n",
    "                    C[u][v] = 0\n",
    "                C[u][v] += 1 / math.log(1+len(users)) # item_users[item] = user\n",
    "    \n",
    "    W = {}\n",
    "    for u, related_users in C.items():\n",
    "        if u not in W.keys():\n",
    "            W[u] = {}\n",
    "        for v, cuv in related_users.items():\n",
    "            W[u][v] = cuv / math.sqrt(N(u)*N(v))\n",
    "    return W"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 以下是基于物品的协同过滤\n",
    "基于物品的协同过率不利用物品内容的属性计算物品之间的相似度，主要通过分析用户的行为记录计算物品之间的相似度。\n",
    "\n",
    "步骤：\n",
    "1、计算物品之间的相似度。\n",
    "2、根据物品的相似度和用户的历史行为给用户生成推荐列表。\n",
    "\n",
    "定义喜欢i物品的用户喜欢j物品的概率（相似度）：$ w_{ij} = \\frac{|N(i)\\cap N(j)|}{|N(i)|}$  \n",
    "|N(i)|表明喜欢i物品的用户数目  \n",
    "但是如果|N(j)|属于热门商品，多数用户都喜欢，那么所有的热门商品的$w_{ij}$都接近1，所以热门物品与其他物品的相似度都接近1，那么无法挖掘冷门商品。  \n",
    "\n",
    "修改相似度计算：\n",
    "$ w_{ij} = \\frac{|N(i)\\cap N(j)|}{\\sqrt{|N(i)||N(j)|}}$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ItemSimilarity(train):\n",
    "    # 计算用户和物品之间的协同过滤\n",
    "    C = {}\n",
    "    N = {}\n",
    "    for user,items in train.items():\n",
    "        for item in items:\n",
    "            if not item in N.keys():\n",
    "                N[item] = 0\n",
    "            if not item in C.keys():\n",
    "                C[item] = {}\n",
    "            N[item] += 1\n",
    "            for itemv in items:\n",
    "                if item == itemv:\n",
    "                    continue\n",
    "                if itemv not in C[item].keys():\n",
    "                    C[item][itemv] = 0\n",
    "                C[item][itemv] += 1\n",
    "    \n",
    "    # 计算相似度\n",
    "    W = {}\n",
    "    for item, related_items in C.items():\n",
    "        if item not in W.keys():\n",
    "            W[item] = {}\n",
    "            for itemv, cuv in related_items.items():\n",
    "                W[item][item] = cuv / math.sqrt(N[item]*N[itemv])\n",
    "    \n",
    "    return W,N,C\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "W,N,C = ItemSimilarity(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': {'b': 1, 'c': 1, 'd': 1},\n",
       " 'b': {'a': 1, 'd': 1, 'e': 1},\n",
       " 'c': {'a': 1, 'd': 1, 'e': 1},\n",
       " 'd': {'a': 1, 'b': 1, 'c': 1, 'e': 1},\n",
       " 'e': {'b': 1, 'c': 1, 'd': 1}}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ItemRecommendation(user,train, W, K):\n",
    "    rank = {}\n",
    "    ru = train[user] # 真实用户喜欢的item\n",
    "    pi = 1\n",
    "    for i in ru:\n",
    "        for j, wj in sorted(W[i].items(),key = lambda x: x[1],reverse=True)[0:K]:\n",
    "            if j in ru:\n",
    "                continue\n",
    "            if j not in rank.keys():\n",
    "                rank[j] = 0\n",
    "            rank[j] += wj*pi\n",
    "    return rank\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "相似度值修改：  \n",
    "因为如果说一个异常的用户，让所有物品的80%的物品都有关联，那么这些物品就都有了相似度，但是其实这个用户的贡献值是我们不需要的。  \n",
    "所以定义Inverse User Frequence:  \n",
    "\n",
    " $$w_{uv} = \\frac{\\sum_{u \\in N(i)\\cap N(j)}\\frac{1}{log(1+|N(u)|)}}{\\sqrt{|N(i)||N(j)|}}$$  \n",
    " |N(u)|是与用户相关的物品数目"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ItemSimilarityChange(train):\n",
    "    # 计算用户和物品之间的协同过滤\n",
    "    C = {}\n",
    "    N = {}\n",
    "    for user,items in train.items():\n",
    "        for item in items:\n",
    "            if not item in N.keys():\n",
    "                N[item] = 0\n",
    "            if not item in C.keys():\n",
    "                C[item] = {}\n",
    "            N[item] += 1\n",
    "            for itemv in items:\n",
    "                if item == itemv:\n",
    "                    continue\n",
    "                if itemv not in C[item].keys():\n",
    "                    C[item][itemv] = 0\n",
    "                C[item][itemv] += 1 / math.log(1+len(items))\n",
    "    \n",
    "    # 计算相似度\n",
    "    W = {}\n",
    "    for item, related_items in C.items():\n",
    "        if item not in W.keys():\n",
    "            W[item] = {}\n",
    "            for itemv, cuv in related_items.items():\n",
    "                W[item][item] = cuv / math.sqrt(N[item]*N[itemv])\n",
    "    \n",
    "    return W,N,C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对用户之间的相似度做归一化处理也可以提高推荐系统的多样性。\n",
    "归一化：  \n",
    "$$w_{ij}^{'} = \\frac{w_{ij}}{max_{j} w_{ij}}$$\n",
    "这样可以对每一个同类物品的相似度最大置为1\n",
    "例如，如果说A类商品的相似度是0.5，B类商品的相似度是0.6，AB类商品之间的相似度是0.2。  \n",
    "如果说用户喜欢5个A类和5个B类的商品，ItemCF推荐的为B，因为相似度大。归一化之后，A，B相似度都是1，那么推荐系统会均匀推荐A和B，提高了推荐系统的多样性。\n",
    "\n",
    "### UserCF 和 ItemCF的差别  \n",
    "\n",
    "UserCF推荐结果注重反映和用户兴趣相似的小群体的热点，ItemCF的推荐结果着重于维系用户的历史兴趣，因为推荐的是跟用户之前喜欢的物品的类似物品。  \n",
    "UserCF的推荐更社会化，反映了用户所在小型兴趣群体种物品的热门程度， ItemCF的推荐更加的个性化，反应了用户自己的兴趣的传承。\n",
    "\n",
    "\n",
    "特征粒度的问题：  \n",
    "e.g.新闻网站，用户的兴趣都不可能特别的细化，因为一般不可能把兴趣的特征细化到喜欢某个话题这么小的粒度，因为话题与情景相关，也就是与当时社会发生的事件可能相关。但是用户每天都会有浏览新闻的习惯，所以只有新闻版面的粗粒度，例如喜欢看社会新闻或者体育新闻。  \n",
    "个性化新闻推荐更加强调抓住新闻的热点，热门程度和时效性是个性化新闻推荐的重点，个性化针对这两点比较次要。  \n",
    "所以这样应该是基于UserCF推荐，因为保证当天新闻的时效性，而且根据相似的用户行为保证了一定程度的个性化。  \n",
    "从技术角度考虑，因为新闻更新速度快，Item的样本容量很大，并且更新很快，所以技术上很难实现，而UserCF只需要用用户相似表，而且用户更新速度远慢于新闻的更新速度。  \n",
    "\n",
    "在图书、电子商务和电影网站：用ItemCF  \n",
    "因为用户的兴趣比较固定和持久，所以应当根据用户的兴趣来设计。并且在这类网站当中，用户的数量一般很大，物品的数目相对较少，与新闻网站相对。\n",
    "\n",
    "\n",
    "#### ItemCF相似度修改：\n",
    "因为$ w_{ij} = \\frac{|N(i)\\cap N(j)|}{\\sqrt{|N(i)||N(j)|}}$ 中，即使对N(j)做了修正，但是N(j)很大的时候，依然会有比较大的相似度。\n",
    "另外一种相似度修改方法：\n",
    "$$ w_{ij} = \\frac{|N(i)\\cap N(j)|}{|N(i)|^{1-\\alpha}|N(j)|^{\\alpha}} $$   \n",
    "$\\alpha = 0.5$是准确率和召回率最高，提高$\\alpha$会降低准确率和召回率，但是会提高覆盖率和新颖性（降低流行度也就是提高新颖性）。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
